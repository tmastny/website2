---
title: Use git to Blog(down) About Your Projects
author: ~
date: '2018-01-20'
slug: git-blogdown-projects-workflow
categories: []
tags: []
description: How to use Git to improve blogdown and project workflow 
draft: true
output:
  blogdown::html_page:
    toc: true 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, 
                      results='show', cache=FALSE, autodep=FALSE)
knitr::read_chunk("periodization-meta-analysis/tidier.R")
```

## Introduction

Here's the scenario: I'm working on my project, using a git repo to track changes. I'm excited about the project or a certain result, and I'd like to tell everyone about it by making a blog post with blogdown.

But how do I utilize all the work I've already done in the project? I've curated the data, built the plots, and saved my complicated analysis as a [`.RDS` file](https://www.fromthebottomoftheheap.net/2012/04/01/saving-and-loading-r-objects/). I'd like to reuse that work, and as a one forum user put it "copying rmarkdown files is a nonstarter."

Inspired by [this discussion](https://community.rstudio.com/t/whats-your-blogdown-workflow-to-include-work-from-other-projects/1445) on the RStudio forum, I'd like to share my workflow that I use to blog about my projects with Hugo/blogdown/Netlify. We'll look at

- [git submodules](https://git-scm.com/book/en/v2/Git-Tools-Submodules)  
- knitr [code externalization](https://yihui.name/knitr/demo/externalization/)

I'll demonstrate this workflow by example. This [Github repo](https://github.com/tmastny/git-blogdown-workflow) will be the external project we'd like to blog about. And this very post is where we'd like to do it. This means you should also follow the `.Rmd` for this post found on my website's [Github repo](https://github.com/tmastny/website2/blob/master/content/blog/2018-01-16-git-blogdown-project-workflow.Rmd).

## git Setup

For our purposes, we'll assume your project repo exists Github. If you don't feel comfortable with command line `git clone/pull/add/commit/push`, I strongly recommend Jenny Bryan's bookdown on [git for R users](http://happygitwithr.com/index.html). The tutorial will teach you the basics of working with git locally and on Github.

The purpose of the submodule is to make the contents of your project easily available and accessible. For example, your `.Rmd` posts can utilize all the data and functions without copy/pasting. And services like Netlify can automatically pull the the project's contents from their github repo without needing a local copy of the project's file in your website's repo. 

All this while maintaining version control and a connection to the project's origin/master so you can incorporate updates.

Note that if you build your own `public` folder to serve your website, you don't need to create a submodule and you can skip to the next section where I introduce `knitr::opts_knit(root.dir = '')`.

### Creating the Submodule

I recommend putting the project submodule in the same directory as your blog post. All my blog posts live here:

```{r, eval=FALSE}
website2/content/blog
```

So that is where I want to put a copy of my project. We do that with the `submodule` command:

```{r, eval = FALSE}
Timothys-MacBook-Pro:blog Tim$ git submodule add https://github.com/tmastny/git-blogdown-workflow.git
Cloning into '/Users/Tim/website2/content/blog/git-blogdown-workflow'...
remote: Counting objects: 10, done.
remote: Compressing objects: 100% (7/7), done.
remote: Total 10 (delta 0), reused 7 (delta 0), pack-reused 0
Unpacking objects: 100% (10/10), done.
```

When we `git add/commit/push` the changes to the [website2 repo](https://github.com/tmastny/website2) you'll notice that the folder icon has changed. This indicates that repo is now tracking a reference to the project repo at a certain commit, rather than a copy of those files at a moment in time.

![](/blog/github_pic.png)

In fact, if you click the folder you will be taken to the [git-blogdown-workflow Github repo](https://github.com/tmastny/git-blogdown-workflow/tree/314984302b4e1576acf6a6af8edfcb69d702c3f8).

This is exactly what we want. Instead of being a static copy of the project's file, we have a version controlled copy that is linked to the master branch. Updates to the submodule are not pulled in automatically, however.

### Updating the Submodule. 

On a normal git repo, to receive the latest changes to your local branch you use `git pull`. But `git pull` only brings in changes to the top level git repo, which is the website's repo. And this is by design.

Imagine you write a post that includes content from a project submodule. Months later a teammate makes an update that changes a feature your blog post depends on. If the submodule was updated automatically with pull, your blog posts could unexpectedly break in surprising ways. 

Therefore, to avoid unexpected conflicts we need to explicitly receive updates from submodules.

The first method is to navigate to the submodule and use `git fetch/merge`. For example,
```{r, eval=FALSE}
Timothys-MacBook-Pro:blog Tim$ cd git-blogdown-workflow/
Timothys-MacBook-Pro:git-blogdown-workflow Tim$ git fetch
remote: Counting objects: 3, done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 3 (delta 1), reused 3 (delta 1), pack-reused 0
Unpacking objects: 100% (3/3), done.
From https://github.com/tmastny/git-blogdown-workflow
   3149843..e207121  master     -> origin/master
Timothys-MacBook-Pro:git-blogdown-workflow Tim$ git merge origin/master
Updating 3149843..e207121
Fast-forward
 plot_model.R | 10 ++++++++++
 1 file changed, 10 insertions(+)
 create mode 100644 plot_model.R
```

Note that `git pull`, the shortcut for `git fetch/merge` used on normal git repos does not work for submodules.

Or if you want to update all your submodules, you can use the shortcut `git submodule update --remote`:

```{r, eval=FALSE}
Timothys-MacBook-Pro:blog Tim$ git submodule update --remote
Submodule path 'git-blogdown-workflow': checked out 'ce0d3a2f200eac6cd2a2980110137f7917e30b1d'
remote: Counting objects: 6, done.
remote: Compressing objects: 100% (4/4), done.
remote: Total 6 (delta 3), reused 5 (delta 2), pack-reused 0
Unpacking objects: 100% (6/6), done.
From https://github.com/tmastny/periodization-meta-analysis
   b29483b..de596ae  master     -> origin/master
Submodule path 'periodization-meta-analysis': checked out 'de596aed6a5535f7f4cdd270644e7993625b3f78'
```

But remember, pulling unexpected changes from your submodules can break your blog posts. 

## Code Externalization by Chunks


To utilize external `.R` scripts, we first need to use `knitr::read_chunk`. 

````
```{r}`r ''`
knitr::read_chunk(path = 'path_name/script.R')
```
````
This will initialize the script within the blog's `.Rmd` environment and allow us to call the code chunks.

In the `.R` script, code chunks will be delimited by this decoration:

```{r, eval = FALSE}
## ---- chunk_name ----
```

To call that chunk within the `.Rmd` session of this blog, we need to do the following:

````
```{r chunk_name}`r ''`
```
````

That will execute the chunk within this session. The results will also be available to use within the blog's `.Rmd` environment. 

Let's work through an example.

### Example 1: The Basics

### r setup
I would encourage you to turn off cache for code utilization. First, since you are pull in external data, in my experience the caching system has gotten confused over the status of a variable. Second, you shouldn't need to do lengthly computations within the blog `.Rmd` environment. Those should be saved as a `.RDS` in your git submodule. We'll work through an example of that latter. 

We'll start simple by working with the R script [`chunks.R`](https://github.com/tmastny/git-blogdown-workflow/blob/master/chunks.R).

Before we can call the chunks in our file, we need to initialize the `.R` script with `read_chunk`.^[You can include the chunk option `echo=FALSE` if you don't want to show `read_chunk` in your blog post. See [here](https://yihui.name/knitr/options/) for more details.] 

````
```{r}`r ''`
knitr::read_chunk(path = 'git-blogdown-workflow/chunks.R')
```
````
```{r}
knitr::read_chunk(path = 'git-blogdown-workflow/chunks.R')
```

This does not execute the code, but allows your blog post's `.Rmd` environment to utilize chunks from that `.R` script. 

After we've initialized the script with `read_chunk`, we can now call the code via the code externalization decorators we've added to the source code of `chunks.R`. For example,

````
```{r simulate_function}`r ''`
```
````
which produces
```{r simulate_function}
```

This really helps with portability and maintainability. We haven't copied any code or scripts. The project script `chunks.R` is being pull from the repo, so if the file is modified there, it will be modified here as well. 

And another useful feature is that calling `simulate_function` evalutes the code in the `.Rmd` environment of the blog post. So we can use the function within the post!

```{r}
monty_hall_sim('a', TRUE)
```

This is nice. We can now easily add simple, exploratory examples to the blog post  that we wouldn't want cluttering the `.R` script. 

Let's call the next chunk:
````
```{r run_simulation}`r ''`
```
````
```{r run_simulation}
```

Now we have the tibble `d` in our blog environment. For example, we can show
```{r}
head(d)
```

You do need to be careful with this data. Any future chunks you call from `chunks.R` evaulate the code in the current environment. So if `d` were gone, the next chunk would fail:
```{r}
a <- d
d <- NULL
```

````
```{r plot_results}`r ''`
```
````
```{r plot_results, error = TRUE}
```

So you need to make sure you don't change the environmental variables in a way future chunks don't except. A good rule of thumb is to not change or make new variables within the blog environment. Only explore and view objects created from the chunks.

Let's fix our mistake and call the plot chunk again.

```{r}
d <- a
```

````
```{r plot_results}`r ''`
```
````
```{r plot_results, fig.width=5, fig.height=4}
```

### Example 2: External Data with `here`

The last example was nice, but a little unrealistic. Usually we use R to work with external data. And when we work with external data we need to be careful of an additonal complication.

Again, we'll do this by example. This time looking at the R script [`fit_model.R`](https://github.com/tmastny/git-blogdown-workflow/blob/master/fit_model.R). 
```{r}
knitr::read_chunk('git-blogdown-workflow/fit_model.R')
```


As you browse this model and the repo, you'll notice that our goal is to analysis the dataset `tidied_periodization.csv`^[We tidied this data set in a previous [blog post](https://timmastny.rbind.io/blog/tidying-messy-spreadsheets-dplyr/).].

The first chunk in `fit_model.R` seems reasonable enough, so let's try it:
```{r read_data, error = TRUE}
```

Ah! The problem is that a file name with no path implies that the file `tidied_periodization.csv` is in the current working directory, which is now `website2/content` or where ever your blog post lives.

Assuming the file is in the working directory of `fit_model.R` works well when executed in the project environment, but fails for the blog post.

The solution^[You could create a symbolic link between `website2/content` and `website2/content/git-blogdown-workflow` but I think that is an unneeded level of overhead. And creating those symbolic links varies between Linux and Windows.]









