---
title: 'Visualizing CPU Pipelining'
author: ~
date: '2024-11-30'
slug: visualizing-cpu-pipeling
categories: []
tags: []
description: 'Visualizing CPU Pipelining'
output:
  blogdown::html_page:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  warning = FALSE, message = FALSE,
  results = "show", cache = FALSE, autodep = FALSE, error = TRUE
)
```

I want to share I've learned about CPU pipelining. 
Thanks to Dan Luu's branch [prediction write-up](https://danluu.com/branch-prediction/)
I was vaguely aware how this worked conceptually, 
but I was motivated to divide into the details after reading
Rodrigo Copetti's [Playstation MIPS write-up](https://www.copetti.org/writings/consoles/playstation/#bibref:9)
where he talked the need for
branch delay slots and how later CPUs used this to as an advantage
with branch *prediction*. I quickly found many subtle and
fasincating details on CPU pipelining that I had to share. 
For more details, I recommend 
chapter 4 of Computer Organization and Design.

This post will assume you are familiar with the [laundry](https://www.cybercomputing.co.uk/Languages/Hardware/laundryAnalogy.html)
or "assembly-line" model of CPU pipelining, but are hazy on some of the
lower-level details. It will also help to have a vague idea of 
the 5-stage MIPS pipeline. 

Let's start by visualizing a basic CPU model that does not have pipelining 
(aka a single-cycle CPU design):

```{=html}
<div id="nonpipeline-container"></div>

<script>
document.addEventListener('DOMContentLoaded', function() {
  const container = document.getElementById('nonpipeline-container');
  container.innerHTML = createPipelineHTML('nonpipelineViz');
  
  window.nonpipelineViz = new PipelineVisualization(
    document.getElementById('nonpipelineViz'),
    {
      instructions: [
        "add $t1",
        "sub $t2",
      ],
      sequence: [
        { pc: 0 },
        { pc: 1, if: "add $t1" },
        { pc: 1, id: "add $t1" },
        { pc: 1, ex: "add $t1" },
        { pc: 1, mem: "add $t1" },
        { pc: 1, wb: "add $t1" },
        { pc: 2, if: "sub $t2" },
        { pc: 2, id: "sub $t2" },
        { pc: 2, ex: "sub $t2" },
        { pc: 2, mem: "sub $t2" },
        { pc: 2, wb: "sub $t2" },
        { pc: null }
      ]
    }
  );
});
</script>
```

One bottleneck is that each individual component of the pipeline 
is inactive while the instruction is actively being processed in
another stage. 

Pipelined CPUs fill in these vacancies by running instructions
through the stages one after the other, rather than waiting
for a single instruction to finish.

```{r, echo=FALSE}
htmltools::includeHTML("pipeline.html")
```

 
```{=html}
<div id="pipeline1-container"></div>

<script>
document.addEventListener('DOMContentLoaded', function() {
  const container = document.getElementById('pipeline1-container');
  container.innerHTML = createPipelineHTML('pipelineViz1');
  
  window.pipelineViz1 = new PipelineVisualization(
    document.getElementById('pipelineViz1'),
    {
      instructions: [
        "add $t1",
        "sub $t2",
        "lw $t3",
        "add $t5",
        "and $t4"
      ],
      sequence: [
        { pc: 0 },
        { pc: 1, if: "add $t1" },
        { pc: 2, if: "sub $t2", id: "add $t1" },
        { pc: 3, if: "lw $t3", id: "sub $t2", ex: "add $t1" },
        { pc: 4, if: "add $t5", id: "lw $t3", ex: "sub $t2", mem: "add $t1" },
        { pc: null, if: "and $t4", id: "add $t5", ex: "lw $t3", mem: "sub $t2", wb: "add $t1" },
        { pc: null, id: "and $t4", ex: "add $t5", mem: "lw $t3", wb: "sub $t2" },
        { pc: null, ex: "and $t4", mem: "add $t5", wb: "lw $t3" },
        { pc: null, mem: "and $t4", wb: "add $t5" },
        { pc: null, wb: "and $t4" },
        { pc: null }
      ]
    }
  );
});
</script>
```

This seems pretty natural: it's like an multiple person assembly line.
But there are some subtle implementation details 
that sets the stage to solve more complicated problems. 

## Instruction Decoding

Instruction decoding orchestrates the entire pipeline
by providing reference fields used the remaining stages.

Let's work through an example (this is not quite how it works). 
Say the instruction is
```
add $t1, $s2, $s3
```
The IF stage fetches the instruction and puts it into 
the ID stage register. Now the ID register contains
fields that will be used by all the remaining stages.
```
pc: 0x014b4820
-> 
Field   op      rs      rt      rd      shamt   funct
Binary  000000  01010   01011   01001   00000   100000
#       add     $s2     $s3     $t1
```

* EX will use `op`, `rs`, and `rt` for the ALU
  operation and inputs
* MEM (for `lw` and `sw`) uses `rt` 
* WB will write to register `rd`

```{r, echo=FALSE}
knitr::include_graphics("id-dep.svg")
```

With pipelining, we have a problem. 
Look at cycle 3 above: `add` moves into EX and `sub` moves into ID.
But WB needs to know the `rd` of the `add` instruction! 
That field used to be safely stored in the ID register, but `sub` overwrote it. 

The solution is to have registers between each pipeline stage
that carry fields from the ID stage (as well as other stages).

```{r, echo=FALSE}
knitr::include_graphics("pipeline-registers.svg")
```

Now when `add` reaches WB, it has the `rd` field so it
can write to the correct register!

## Hazard detection 

The field metadata from ID needs to be available at each stage
to enable basic operations like writing back to the registers, 
but the feilds also turn out to be crucial to solve data hazards. 

To start, let's look at this example:
```{=html}
<div id="pipelineblocked-container"></div>

<script>
document.addEventListener('DOMContentLoaded', function() {
  const container = document.getElementById('pipelineblocked-container');
  container.innerHTML = createPipelineHTML('pipelineblocked');
  
  window.pipelineblocked = new PipelineVisualization(
    document.getElementById('pipelineblocked'),
    {
      instructions: [
        "add r3, r1, r4",
        "sub r5, r3, r6"
      ],
      sequence: [
        { pc: 0 },
        { pc: 1, if: "add r3, r1, r4" },
        { pc: 2, if: "sub r5, r3, r6", id: "add r3, r1, r4" },
        { pc: null, id: "sub r5, r3, r6", ex: "add r3, r1, r4" },
      ]
    }
  );
});
</script>
```

`sub` has a dependency on the output of `add`: this is called a 
data hazard. Structurally, the CPU could proceed but the result 
would be incorrect. We need a way to check if any of the inputs
of the instruction in ID is the output register for any downstream 
instructions. 

Since the field metadata is propogated to each stage register,
we have all the data we need! What's missing is a unit to calculate
this:
```
ID/EXE.rs == EX/MEM.rd || ID/EXE.rt == EX/MEM.rd ||
ID/MEM.rs == MEM/WB.rd || ID/MEM.rt == MEM/WB.rd
```

That's the *Hazard Detection Unit*. This unit will attach to
the ID stage and prevent progress until the hazard is resolved.





Using the metadata stored in registers, we can add
a hazard detection unit.

```{=html}
<div id="pipeline2-container"></div>

<script>
document.addEventListener('DOMContentLoaded', function() {
  const container = document.getElementById('pipeline2-container');
  container.innerHTML = createPipelineHTML('pipelineViz2');
  
  window.pipelineViz2 = new PipelineVisualization(
    document.getElementById('pipelineViz2'),
    {
      instructions: [
        "add r3, r1, r4",
        "sub r5, r3, r6"
      ],
      sequence: [
        { pc: 0 },
        { pc: 1, if: "add r3, r1, r4" },
        { pc: 2, if: "sub r5, r3, r6", id: "add r3, r1, r4" },
        { pc: null, id: "sub r5, r3, r6", ex: "add r3, r1, r4" },
        { pc: null, id: "sub r5, r3, r6", mem: "add r3, r1, r4" },
        { pc: null, id: "sub r5, r3, r6", wb: "add r3, r1, r4" },
        { pc: null, ex: "sub r5, r3, r6" },
        { pc: null, mem: "sub r5, r3, r6" },
        { pc: null, wb: "sub r5, r3, r6" },
        { pc: null }
      ]
    }
  );
});
</script>
```
