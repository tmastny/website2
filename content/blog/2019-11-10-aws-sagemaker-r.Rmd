---
title: 'AWS Sagemaker and R'
author: ~
date: '2019-11-27'
slug: aws-sagemaker-r
categories: []
tags: []
description: 
output:
  blogdown::html_page:
    toc: true 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, 
                      results='show', cache=FALSE, autodep=FALSE)
```

## Introduction

I'm excited to announce my 
[sagemaker R package](https://github.com/tmastny/sagemaker)!

AWS Sagemaker is a powerful tool, 
and I hope my package makes it easier for people to try it out!

Since the Github page and [website](https://tmastny.github.io/sagemaker/)
already introduce the sagemaker R package, 
I want to use this blog post to introduce AWS Sagemaker,
productionizing machine learning, and how the my sagemaker R package fits in.

## AWS Sagemaker

AWS Sagemaker is a platform for training machine learning models.

There are three components of Sagemaker:

1. hosted development environment with juypter notebooks
2. scalable training of machine learning models
3. endpoint and batch predictions from trained models

Hosted juypter notebooks are a great feature, 
but this post will focus on Sagemaker's scalable training and predictions.

### AWS cost
 
Before you use Sagemaker you need an AWS account. 
AWS requires your credit card information so they can charge you for use
of services.

However, by taking advantage of free tier services 
and closely monitoring usage, it's possible to keep costs low. 

Here is my Spend Summary for the entire time I developed the R package:

* Total Spend: $4.05 
  - By service: 
    - Sagemaker: $4.05
    - Other services: $0.00
  
* Free Tier Usage
  - S3 Put: 28%
  - S3 Get: 4.2%
  - Others: <1%
  
So if you are interested in learning AWS, 
but aren't in an enterprise environment,
it is definitely possible to get started.

## Productionizing machine learning predictions

Before we dive into AWS Sagemaker, 
let me introduce my mental model for generating machine learning
predictions:

![](/blog/predictions-pipeline.svg)

The workflow on the bottom is similar to the data exploration workflow shown in
[R for Data Science](https://r4ds.had.co.nz/explore-intro.html). 
We process data, evaluate, and select a model to deploy.

On the top, the key to repeatable, scheduled predictions is the
_predictions pipeline environment_. 
A mature environment might be a docker image ran by AWS Batch, 
scheduled by a CRON trigger on Jenkins. 
A simple one would be an Rscript ran once a day on your desktop.

Think of the pipeline like a function, deployed on a certain trigger:

```{r echo = FALSE}
emo::clock(Sys.time())
```

```{r}
pipeline <- function(...) {
  data <- fetch_data(...) %>%
    transform(...)
  
  model <- sagemaker::sagemaker_attach_tuner(...)
  predict(model, data)
}
```

One key feature of the environment is that processes are shared
with the training workflow. 

For example, any data transformation or feature engineering process
must be shared between the training workflow and the predictions pipeline.
Otherwise, your predictions will not be reliable, 
and your model might not even run against the new data if its a different shape.

Likewise, the pipeline needs to use the model we selected during training.

## Sagemaker Features

### Training and Evaluation

Sagemaker has tools for scalable training of machine learning models.
You can choose the compute power and parallel model building
suitable for the scale of your training task.

In the R package, this is done by
```r
sagemaker::sagemaker_estimator
sagemaker::sagemaker_hyperparameter_tuner
```

The training also facilitates hyperparameter tuning for selection. 
Sagemaker also has some tools to help you evaluate tuning and model fit:

```r
sagemaker::sagemaker_tuning_job_logs
sagemaker::sagemaker_training_job_logs
```


### Deployment

In the _predictions pipeline environment_, 
Sagemaker can also provide a scalable model to service predictions.

Sagemaker offers real-time predictions, scalable both in terms of 
compute speed and parallel servicing.

In our pipeline example, this means that our pipeline function
sends data to the Sagemaker endpoint, and receives predictions back.

```{r echo = FALSE}
emo::clock(Sys.time())
```

```{r}
pipeline <- function(...) {
  data <- fetch_data(...) %>%
    transform(...)
  
  model <- sagemaker::sagemaker_attach_tuner(...)
  # sagemaker::sagemaker_deploy_endpoint(model)
  
  # sends and receives data
  # predict.sagemaker
  predict(model, data)
}
```

It can also run batch processing, 
making one-off predictions on datasets in S3.

If used in the pipeline, this means that
our pipeline must have permission to spin up Sagemaker resources.

```{r echo = FALSE}
emo::clock(Sys.time())
```

```{r}
pipeline <- function(...) {
  data <- fetch_data(...) %>%
    transform(...)
  
  model <- sagemaker::sagemaker_attach_tuner(...)
  
  # creates Sagemaker resources
  sagemaker::batch_predict(model, data, ...)
}
```

So with the Sagemaker endpoint, Sagemaker resources have already been created
and are persistent. The pipeline environment sends and receives data
to the endpoint.

For batch predictions, resources need to be temporarily created and destroyed. 
The pipeline environment must have permission and access to use Sagemaker.

## What Sagemaker isn't

Unfortunately, Sagemaker does not provide services for the
entire _predictions pipeline environment_. 
Most of the complexity comes from the environment itself,
which is usually a docker image.

You will also be responsible for reusing the transformation and
feature engineering process from the training pipeline. 
Scheduling is managed outside of the environment. 

Ultimately, Sagemaker will only act as an API service to generate
predictions for that environment.

## sagemaker R package

So how does the new sagemaker R package fit into this?^[
https://aws.amazon.com/blogs/machine-learning/using-r-with-amazon-sagemaker/  http://www.rpubs.com/TimFlocke/SageMaker_R_demo ] 
First and foremost, the sagemaker R package is an interface
to the AWS Sagemaker API. This means that it's easier to build
a _predictions pipeline environment_ using R. 

This means you can do all your data maniuplation and cleaning from R, 
as well as manage your Sagemaker APIs.

Second, I think this R package vastly simplifies the Sagemaker interface,
especially during model training and evaluation. 
It's easier to compare hyperparameters across tuning jobs, 
and make predictions on new data.

Most importantly, I've tried to hide a lot of the details that
get in the way when you are trying to quickly spin up a Sagemaker
model. Less boilerplate, more machine learning.

## Limitations

This package has been built for and tested on the xgboost Sagemaker models.
I spent most of my time working with xgboost, so I've even included 
shortcuts for xgboost like 
`sagemaker_xgb_container` and `sagemaker_xgb_estimator`.

However, this means there are a lot of models and features of Sagemaker
I might not have come across. 
If for whatever reason, something in `sagemaker` doesn't work 
leave an issue here: https://github.com/tmastny/sagemaker/issues

## What's next

I think there are many small improvements to help with the everyday stuff,
like adding a `type` parameter on `predict` for probability or class.

I also have bigger projects I want to tackle. 
The lack of cross-validation on Sagemaker has always disappointed me, 
and I think it's possible to implement.

And as always, 
I'll need to keep developing and maintaining functionality 
as I develop more models and use more features and models.

